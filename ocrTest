import cv2
import pytesseract
import numpy as np
import matplotlib.pyplot as plt
import time
import os


def getVProjection(image):
    vProjection = np.zeros(image.shape, np.uint8);
    (h, w) = image.shape
    print('img w:', w, ',h:', h)
    # 長度與圖寬一致的組
    w_ = [0] * w

    # 循環統計每一列白色像素的個數
    for x in range(w):
        for y in range(h):
            if image[y, x] == 255:
                w_[x] += 1

    # 繪製垂直平投影圖像
    for x in range(w):
        for y in range(h - w_[x], h):
            vProjection[y, x] = 255

    # cv2.imshow('vProjection',vProjection)

    return w_


def findPaths(directory):
    # directory = r'/Users/moriakiraakira/Desktop/OCR_Sample/cathayOCR/Source'
    filePaths = []
    for entry in os.scandir(directory):
        if (entry.path.endswith(".jpg")
            or entry.path.endswith(".png")) and entry.is_file():
            print(entry.path)
            filePaths.append(entry.path)
    return filePaths


def cathayOCR(origineImage, resize_num=3, threshold=150, erodeIterationTimes=3, dilateIterationTimes=3,
              medianBlurKernel=7, isRevert=True):
    isShowImg = True

    origineImage = cv2.copyMakeBorder(origineImage, 1, 1, 1, 1, cv2.BORDER_CONSTANT, value=[255, 255, 255])
    # resize
    origineImage = cv2.resize(origineImage,
                              (origineImage.shape[1] * int(resize_num), origineImage.shape[0] * int(resize_num)),
                              interpolation=cv2.INTER_CUBIC)

    # gray
    grayImg = cv2.cvtColor(origineImage, cv2.COLOR_BGR2GRAY)

    # sharpen
    kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]], np.float32)
    sharpenImg = cv2.filter2D(grayImg, -1, kernel=kernel)

    # binary
    retval, binImg = cv2.threshold(sharpenImg, threshold, 255, cv2.THRESH_BINARY_INV)

    # erode
    erodeImg = cv2.erode(binImg, (5, 5), iterations=erodeIterationTimes)

    # dilate
    dilateImg = cv2.dilate(erodeImg, (5, 5), iterations=dilateIterationTimes)

    # medianBlur
    medianBImg = cv2.medianBlur(dilateImg, medianBlurKernel)

    # 反相
    if isRevert:
        resultImg = 255 - medianBImg
    else:
        resultImg = medianBImg

    # 分割
    Position = []
    W = getVProjection(medianBImg)
    H_Start = 0
    H_End = np.size(medianBImg, 0)
    Wstart = 0
    Wend = 0
    W_Start = 0
    W_End = 0
    for j in range(len(W)):
        if W[j] > 0 and Wstart == 0:
            W_Start = j
            Wstart = 1
            Wend = 0
        if W[j] <= 0 and Wstart == 1:
            W_End = j
            Wstart = 0
            Wend = 1
        if Wend == 1:
            Position.append([W_Start, H_Start, W_End, H_End])
            Wend = 0
    splitImg = []
    splitImgW = 40  # 切割後固定每張圖的寬度
    for m in range(len(Position)):
        cv2.rectangle(origineImage, (Position[m][0], Position[m][1]), (Position[m][2], Position[m][3]), (0, 255, 255),
                      1)
        tmpH = Position[m][3] - Position[m][1]
        tmpW = Position[m][2] - Position[m][0]
        tmpImg = resultImg[Position[m][1]:Position[m][1] + tmpH, Position[m][0]:Position[m][0] + tmpW]
        tmpW = tmpImg.shape[1]
        paddingW = int(splitImgW / 2 - tmpW / 2)
        # 切割後等寬
        if tmpW < splitImgW:
            if tmpW % 2 > 0:
                tmpImg = cv2.copyMakeBorder(tmpImg, 0, 0, paddingW + 1, paddingW, cv2.BORDER_CONSTANT,
                                            value=[255, 255, 255])
            else:
                tmpImg = cv2.copyMakeBorder(tmpImg, 0, 0, paddingW, paddingW, cv2.BORDER_CONSTANT,
                                            value=[255, 255, 255])
        splitImg.append(tmpImg)

    # -----------------------------------
    # contour
    # w_max = 0
    # contours, hierarchy = cv2.findContours(medianBImg, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    # for c in contours:
    #     x, y, w, h = cv2.boundingRect(c)
    #     if w>w_max:
    #         w_max = w
    #     #cv2.rectangle(origineImage, (x, y), (x + w, y + h), (0, 255, 0), 2, cv2.LINE_AA)
    # #cv2.imshow('origineImage', origineImage)
    # print('w_max:',w_max)
    # result = []
    # tmpRotate=[]
    # # 用boundingRect的值算出每個box的頂點
    # for contour in contours:
    #     x, y, w, h = cv2.boundingRect(contour)
    #     #-------旋轉框
    #     rect = cv2.minAreaRect(contour)
    #     box = cv2.boxPoints(rect)
    #     box = np.int0(box)
    #     tmpRotate.append(box)
    #     #-------
    #     if w == w_max:  # w_max是所有contonur的寬度中最寬的值
    #         box_left = [[x, y], [x + int(w / 2), y], [x + int(w / 2), y + h], [x, y + h]]
    #         box_right = [[x + int(w / 2), y], [x + w, y], [x + w, y + h],[x + int(w / 2), y + h]]
    #         result.append(box_left)
    #         result.append(box_right)
    #     else:
    #         box = np.int0([[x, y], [x + w, y], [x + w, y + h], [x, y + h]])
    #         result.append(box)
    # npresult = np.array(result)
    # npTmpRotate = np.array(tmpRotate)
    # #畫旋轉框
    # #for box in npTmpRotate:
    #     #cv2.drawContours(origineImage, [box], 0, (255, 255, 0), 2)
    # #畫一般框
    # #for box in npresult:
    #     #cv2.drawContours(origineImage, [box], 0, (0, 0, 1), 1)

    # 秀圖
    if isShowImg:
        plt.subplot(331), plt.title('oriImg'), plt.imshow(origineImage)
        plt.subplot(332), plt.title('grayImg'), plt.imshow(grayImg, cmap='gray', vmin=0, vmax=255)
        plt.subplot(333), plt.title('sharpenImg'), plt.imshow(sharpenImg, cmap='gray', vmin=0, vmax=255)

        plt.subplot(334), plt.title('binImg'), plt.imshow(binImg, cmap='gray', vmin=0, vmax=255)
        plt.subplot(335), plt.title('erodeImg'), plt.imshow(erodeImg, cmap='gray', vmin=0, vmax=255)
        plt.subplot(336), plt.title('dilateImg'), plt.imshow(dilateImg, cmap='gray', vmin=0, vmax=255)
        plt.subplot(337), plt.title('medianBlur'), plt.imshow(medianBImg, cmap='gray', vmin=0, vmax=255)
        plt.subplot(338), plt.title('resultImg'), plt.imshow(resultImg, cmap='gray', vmin=0, vmax=255)
        plt.show()
        for i in range(len(splitImg)):
            plt.subplot(220 + i + 1), plt.imshow(splitImg[i], cmap='gray', vmin=0, vmax=255)
        plt.show()

    # 產出切割文字檔
    resultText = []
    for img in splitImg:
        resultChar = pytesseract.image_to_string(img, lang='eng',
                                                 config='--psm 10 -c tessedit_char_whitelist=abcdefghijklmnopqrstuvwxyz0123456789')
        timestamp = int(time.time() * 1e6)
        filePath = "/Users/moriakiraakira/Desktop/OCR_Sample/cathayOCR/Result/{resultChar}_{timestamp}.png".format(
            resultChar=resultChar, timestamp=timestamp)
        cv2.imwrite(filePath, img)
        resultText.append(resultChar)
    return resultText


if __name__ == "__main__":
    # path = '/Users/moriakiraakira/Desktop/OCR_Sample/Source/2-4.png'
    # origineImage = cv2.imread(path)
    # print(cathayOCR(origineImage))

    # 滾來源資料夾所有檔案 直接產出切割檔
    filePaths = findPaths(r'/Users/moriakiraakira/Desktop/OCR_Sample/cathayOCR/Source')
    for filePath in filePaths:
        origineImage = cv2.imread(filePath)
        print(cathayOCR(origineImage))
